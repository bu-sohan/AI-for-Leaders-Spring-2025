{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0392320-e3f8-4e08-a7f2-373d91054cae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48a74b5e-5180-4544-86a0-b047a877eb8e",
   "metadata": {},
   "source": [
    "# Week 1 - Preprocessing\n",
    "\n",
    "## Please run the cells of the notebook as you get to them while reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c24f12c-b364-40f0-b295-7c1ba88be680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c513ee-9d2b-408f-bbcd-33fa70a299e8",
   "metadata": {},
   "source": [
    "# 1. Lesson on how to search for Python commands\n",
    "\n",
    "Let's consider a few possible ways to learn about Python programming.  Let's suppose you want to learn how to produce a short summary of the information in your DataFrame.\n",
    "\n",
    "1. Your **instructor** could provide the information.\n",
    "\n",
    "You could be provided with a lesson about functions like info() and describe().  If you have a pandas DataFrame called df, then you can summarize its contents using df.info() or df.describe().  df.info() provides a list of column names with their counts and data types.  df.describe() will provide information such as the mean, min, max, standard deviation, and quantiles.  Thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d97ef1-f92d-45a1-89e6-efea4d42ba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.290994</td>\n",
       "      <td>1.290994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.750000</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B\n",
       "count  4.000000  4.000000\n",
       "mean   2.500000  5.500000\n",
       "std    1.290994  1.290994\n",
       "min    1.000000  4.000000\n",
       "25%    1.750000  4.750000\n",
       "50%    2.500000  5.500000\n",
       "75%    3.250000  6.250000\n",
       "max    4.000000  7.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 4], [2, 5], [3, 6], [4, 7]], columns = ['A', 'B'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541ee48-fb69-40d5-8b39-8f1b02918a9e",
   "metadata": {},
   "source": [
    "In this describe() result, we see that the two columns A and B each have four elements.  The means and other statistics are shown.\n",
    "\n",
    "2. You could look up the information on **Google**.\n",
    "\n",
    "If I Google the question \"how do I briefly summarize the contents of a dataframe using Python,\" I receive the following link (among others), which discusses the describe() command mentioned above:\n",
    "\n",
    "https://www.w3schools.com/python/pandas/ref_df_describe.asp\n",
    "\n",
    "It also provide the complete usage information:\n",
    "\n",
    "dataframe.describe(percentiles, include, exclude, datetime_is_numeric)\n",
    "\n",
    "It explains that \"percentiles\" is set by default to [0.25, 0.5, 0.75] but we could change that.  Let's try it!  Since there are three intervals here rather than four, it might be more meaningful to ask about a 33rd and 67th percentile rather than 25, 50, and 75.  We can use 1/3 for 0.33 and 2/3 for 0.67 to get the exact percentile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aea76dd-f492-4bbe-9431-8e1a41cf0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.290994</td>\n",
       "      <td>1.290994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.3%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.7%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B\n",
       "count  4.000000  4.000000\n",
       "mean   2.500000  5.500000\n",
       "std    1.290994  1.290994\n",
       "min    1.000000  4.000000\n",
       "33.3%  2.000000  5.000000\n",
       "50%    2.500000  5.500000\n",
       "66.7%  3.000000  6.000000\n",
       "max    4.000000  7.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 4], [2, 5], [3, 6], [4, 7]], columns = ['A', 'B'])\n",
    "df.describe(percentiles = [1/3, 2/3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd06ce3-edf9-4786-982d-5650fc22ca58",
   "metadata": {},
   "source": [
    "Apparently, the 50% value (the median) stays even though we did not specifically request it.\n",
    "\n",
    "3. You could look up the official **documentation**.\n",
    "\n",
    "Now that we know we want the pandas describe() function, try Googling: pandas documentation describe.\n",
    "\n",
    "Here is the general documentation page for pandas:\n",
    "\n",
    "https://pandas.pydata.org/docs/index.html\n",
    "\n",
    "Here is the specific page for the describe() function:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "When I look at this, it appears to be showing the most recent (currently 2.2) version of pandas; this is shown in the upper right corner.\n",
    "\n",
    "4. You could also ask **ChatGPT**.\n",
    "\n",
    "Let's try it.  ChatGPT, \"how do I briefly summarize the contents of a dataframe using Python\"\n",
    "\n",
    "When I do this, ChatGPT mentions describe() among other options, but does not go into detail.  However, I could ask it.  ChatGPT, \"tell me more about describe() in Python for summarizing dataframes.\"\n",
    "\n",
    "Then, I get a good explanation of describe(), although it does not mention the percentiles option.  One advantage of using Google or the documentation in addition of ChatGPT is that these sources may provide interesting information that does not directly answer our question.  Thus, we might not have known about the various arguments, such as percentiles, if we only used ChatGPT.  A second issue is that ChatGPT sometimes hallucinates (it makes up information).  In general, by examining multiple sources - Google, documentation, and ChatGPT - we can get more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cede07d-03a8-4c36-b5ca-67619bbfd365",
   "metadata": {},
   "source": [
    "# 2. Weekly graph question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71d462-12df-4b94-b34f-4d43e4d289d7",
   "metadata": {},
   "source": [
    "In Storytelling With Data, on page 1: examine the pie chart graph in the upper left corner of the graphs.  Please write a short explanation of the pros and cons of this graph.  What do you think of the choice of pie chart as a format?  The color scheme?  The legend?  The title?  How would you draw it differently if you were creating this graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a150f",
   "metadata": {},
   "source": [
    "This is a basic pie chart showing survery result percentage of various categories. It's an okay chart. It is a bit difficult to relate percentage with the categories in the graph. The category labels should have been incororated within the chart. The colors needed to be more distinguishable from one another.  I think the result is better displayed on a bar chart to clearly show different categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a54048-d621-47b9-aa65-4b46d9c3bb4c",
   "metadata": {},
   "source": [
    "# 3. Homework - Bank Customers\n",
    "\n",
    "I will begin by creating a file for you to analyze.  I will show you all of the steps I used to create it.  Please run this code in order to create and save a file about bank customers.\n",
    "\n",
    "### The numbered problems are for you to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2950b5f1-9ab8-452f-b9d7-31ce82bbf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_customers = 100\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95561d16-3aac-4537-841a-835272775080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank = pd.DataFrame(columns = [\"CustomerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e84ff91-47c6-4788-b56b-1d63a2b06a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank[\"CustomerID\"] = [str(x) for x in np.arange(num_customers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5983f3fb-8341-4bb0-92be-850dd712c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(1950, 1, 1)\n",
    "end = datetime(2024, 1, 1)\n",
    "numdays = (end - start).days\n",
    "random_days = np.random.randint(0, numdays, size = num_customers)\n",
    "df_bank[\"BirthDate\"] = start + pd.to_timedelta(random_days, unit='D')\n",
    "df_bank[\"BirthDate\"] = df_bank[\"BirthDate\"].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64adeb78-6b2c-46df-a4f0-8aee5fa75f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ssn_string(num):\n",
    "    ssn_str = f'{num:09}'\n",
    "    return ssn_str[0:3] + \"-\" + ssn_str[3:5] + \"-\" + ssn_str[5:9]\n",
    "ssn_vector_func = np.vectorize(make_ssn_string)\n",
    "df_bank[\"SSN\"] = ssn_vector_func(np.random.randint(0, 999999999, size = num_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8e00bb-2f97-4e11-a95f-138baf44206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank[\"AccountID\"] = np.random.randint(0, num_customers, size = num_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc41db6c-9e4a-4efc-af0d-9f921bb77ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_days = np.random.randint(0, 365 * 80, size = num_customers)\n",
    "df_bank[\"AccountOpened\"] = (pd.to_datetime(df_bank[\"BirthDate\"]) + pd.to_timedelta(random_days, unit='D')).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2ddf02-7ef2-485a-8d1a-1049b30630dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank.loc[0, \"BirthDate\"] = \"1980\"\n",
    "df_bank.loc[1, \"BirthDate\"] = \"no date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5e52d8f-10b5-433f-bcfa-9d50232041e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank.loc[2, \"AccountID\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb0d5e7-1bcb-48f0-ab70-c7c3d4b8bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank[\"AccountType\"] = np.random.choice([\"checking\", \"savings\", \"cd\"], size = num_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a2bef-d599-4599-b555-7a01c2cd3fb3",
   "metadata": {},
   "source": [
    "Load the bank_customers.csv file.  (There is no practical reason to save it, then load it - we're just demonstrating how this would be done.)\n",
    "I am calling the loaded df by a new name, df_bank_loaded, to make clear why it's not the same variable as the old df.  Of course, in actuality the two contain the exact same data!  But it's good to get in the habit of naming things carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15dea7e7-619d-4d3f-aa72-712f3da7d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank.loc[num_customers - 1] = df.loc[0]\n",
    "df_bank.to_csv(\"bank_customers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf79336-ba67-446e-8220-e77534c4c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank_loaded = pd.read_csv(\"bank_customers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380145bb-e051-418d-b3d2-ad032cab375b",
   "metadata": {},
   "source": [
    "1. Use describe() and info() to analyze the data.   Also, look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b77c8936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>AccountID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>46.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.722813</td>\n",
       "      <td>27.679358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.500000</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.500000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CustomerID  AccountID\n",
       "count   99.000000  98.000000\n",
       "mean    49.000000  46.551020\n",
       "std     28.722813  27.679358\n",
       "min      0.000000   0.000000\n",
       "25%     24.500000  25.500000\n",
       "50%     49.000000  42.000000\n",
       "75%     73.500000  71.000000\n",
       "max     98.000000  97.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank_loaded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b13f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   CustomerID     99 non-null     float64\n",
      " 1   BirthDate      99 non-null     object \n",
      " 2   SSN            99 non-null     object \n",
      " 3   AccountID      98 non-null     float64\n",
      " 4   AccountOpened  99 non-null     object \n",
      " 5   AccountType    99 non-null     object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bank_loaded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897936c-9af9-4344-bdb7-6290d8b34bce",
   "metadata": {},
   "source": [
    "Suggested Google Search or ChatGPT prompt: \"how do I use the describe function in python\"\n",
    "\n",
    "Example Google result: https://www.w3schools.com/python/pandas/ref_df_describe.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fb74ed3-871e-41b6-99f5-da7eb3a37712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>SSN</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>AccountOpened</th>\n",
       "      <th>AccountType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>530-47-1866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1959-12-06</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>no date</td>\n",
       "      <td>682-76-9175</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2039-02-20</td>\n",
       "      <td>cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1976-12-15</td>\n",
       "      <td>377-98-9839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2003-10-18</td>\n",
       "      <td>474-05-7613</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2004-03-02</td>\n",
       "      <td>cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1985-12-06</td>\n",
       "      <td>750-55-5509</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2059-05-05</td>\n",
       "      <td>cd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   BirthDate          SSN  AccountID AccountOpened AccountType\n",
       "0         0.0        1980  530-47-1866        4.0    1959-12-06    checking\n",
       "1         1.0     no date  682-76-9175       67.0    2039-02-20          cd\n",
       "2         2.0  1976-12-15  377-98-9839        NaN    2019-03-25    checking\n",
       "3         3.0  2003-10-18  474-05-7613       86.0    2004-03-02          cd\n",
       "4         4.0  1985-12-06  750-55-5509       77.0    2059-05-05          cd"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first few rows\n",
    "df_bank_loaded.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6062d1d-bf7f-4e81-8d19-60bd160c02d5",
   "metadata": {},
   "source": [
    "If you used describe() and info(), you now know that BirthDate and AccountOpened are strings.  But we want them to be dates.  Let's convert them to dates (or Timestamps in pandas).  When we try this, we get a ValueError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89e37c09-aee4-49f5-abc5-1e6ec9837b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError for BirthDate: time data \"1980\" doesn't match format \"%Y-%m-%d\", at position 0. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_bank_loaded[\"BirthDate\"] = pd.to_datetime(df_bank_loaded[\"BirthDate\"], format='%Y-%m-%d')\n",
    "    print(\"It worked!\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError for BirthDate: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbcb584b-134b-475b-8fd4-70ca1ba7d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It worked!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_bank_loaded[\"AccountOpened\"] = pd.to_datetime(df_bank_loaded[\"AccountOpened\"], format='%Y-%m-%d')\n",
    "    print(\"It worked!\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError for AccountOpened: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b1ccf-1001-40ab-b026-beae68b7fd19",
   "metadata": {},
   "source": [
    "The simple way to fix this is to remove the rows that have bad dates for BirthDate.  I Googled:\n",
    "\n",
    "\"How to remove rows from a dataframe that have poorly formatted dates using python\"\n",
    "\n",
    "https://stackoverflow.com/questions/21556744/pandas-remove-rows-whose-date-does-not-follow-specified-format\n",
    "\n",
    "This recommends that I verify that the date is a string of length 10, because YYYY-MM-DD has that length:\n",
    "\n",
    "df1\\[df1.BirthDate.str.len() !=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70ec53a1-2de5-48b5-9942-6857495e2b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bank_loaded[df_bank_loaded.BirthDate.str.len() == 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4edac07-185c-45ad-ba95-cca56bca0c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>SSN</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>AccountOpened</th>\n",
       "      <th>AccountType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>530-47-1866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1959-12-06</td>\n",
       "      <td>checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>no date</td>\n",
       "      <td>682-76-9175</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2039-02-20</td>\n",
       "      <td>cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CustomerID BirthDate          SSN  AccountID AccountOpened AccountType\n",
       "0          0.0      1980  530-47-1866        4.0    1959-12-06    checking\n",
       "1          1.0   no date  682-76-9175       67.0    2039-02-20          cd\n",
       "99         NaN       NaN          NaN        NaN           NaT         NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank_loaded[df_bank_loaded.BirthDate.str.len() != 10].iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503d01f-0168-43f9-a271-6f529e47886f",
   "metadata": {},
   "source": [
    "Now we can make this permanent, creating a new DataFrame df_bank_datefix.\n",
    "I am making a copy in order to ensure that df_bank_datefix is a new DataFrame rather than being a slice of the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1bed857-0d03-4091-9838-fd75227c63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank_datefix = df_bank_loaded[df_bank_loaded.BirthDate.str.len() == 10].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838e568e-a333-4d18-ba8d-84c2926191e8",
   "metadata": {},
   "source": [
    "Test again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8655d6a-0a79-42c4-891a-cb421d664ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It worked!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_bank_datefix[\"BirthDate\"] = pd.to_datetime(df_bank_datefix[\"BirthDate\"], format='%Y-%m-%d')\n",
    "    print(\"It worked!\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88b739-9481-46fd-a8bd-996ed0e0bc2f",
   "metadata": {},
   "source": [
    "2. To check that it worked, use a summary function that will tell you if the BirthDate field is now a datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce550219-274c-4e3c-953d-cdf920a37990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97 entries, 2 to 98\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   CustomerID     97 non-null     float64       \n",
      " 1   BirthDate      97 non-null     datetime64[ns]\n",
      " 2   SSN            97 non-null     object        \n",
      " 3   AccountID      96 non-null     float64       \n",
      " 4   AccountOpened  97 non-null     datetime64[ns]\n",
      " 5   AccountType    97 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(2)\n",
      "memory usage: 5.3+ KB\n",
      "2    1976-12-15\n",
      "3    2003-10-18\n",
      "4    1985-12-06\n",
      "5    2008-02-29\n",
      "6    1975-04-05\n",
      "        ...    \n",
      "94   1969-03-14\n",
      "95   1975-09-23\n",
      "96   1989-03-09\n",
      "97   1960-09-23\n",
      "98   1975-08-17\n",
      "Name: BirthDate, Length: 97, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Check the data type of BirthDate\n",
    "\n",
    "df_bank_datefix.info()\n",
    "\n",
    "print(df_bank_datefix[\"BirthDate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ac0d0-be31-4c50-838d-f104463a8114",
   "metadata": {},
   "source": [
    "3. Check whether there are any null values in the DataFrame.  If so, remove those rows or (if you prefer) fill in the value with an appropriate number.\n",
    "\n",
    "First try at a Google search or ChatGPT prompt: \"how do I find out if there are any null values in a pandas DataFrame?\"\n",
    "\n",
    "This page gives an answer.  Unfortunately, it took my request too literally: it tells me only if there are any, and not which rows have them.  On reflection, that's not really what I want - I think I asked the wrong question.  I want to see the rows, not just _whether_ there are any.\n",
    "\n",
    "https://stackoverflow.com/questions/29530232/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe\n",
    "\n",
    "ChatGPT likewise doesn't give the answer I want - because I asked the wrong question.\n",
    "\n",
    "Next try at a Google search or ChatGPT prompt: \"how do I check which rows have null values in a pandas DataFrame?\"\n",
    "\n",
    "This page gives an answer:\n",
    "\n",
    "https://stackoverflow.com/questions/36226083/how-to-find-which-columns-contain-any-nan-value-in-pandas-dataframe\n",
    "\n",
    "ChatGPT also gives a good answer.  I recommend looking at both of them!\n",
    "\n",
    "Now try it on your own:\n",
    "\n",
    "Suggested Google search or ChatGPT prompt: \"how do I remove rows with null values in a pandas DataFrame?\"\n",
    "\n",
    "Suggested Google search or ChatGPT prompt: \"how do I fill in null values in a pandas DataFrame?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8ffaf2e-a8b2-42a2-ad09-e014431fccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "CustomerID       0\n",
      "BirthDate        0\n",
      "SSN              0\n",
      "AccountID        1\n",
      "AccountOpened    0\n",
      "AccountType      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values\n",
    "print(df_bank_datefix.isnull().values.any())\n",
    "\n",
    "# Removing the null values\n",
    "df_bank_datefix.dropna()\n",
    "\n",
    "# Verify nulls are removed\n",
    "\n",
    "print(df_bank_datefix.isnull().sum())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca88fe-0b67-473e-965f-7e5da13f2a02",
   "metadata": {},
   "source": [
    "4. Find out if there are any duplicate rows (two rows exactly the same).  List their row numbers.  Then remove the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf0983-4861-486b-bfc0-942b6772c866",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find out if there are any duplicate rows in a DataFrame using Python\"\n",
    "\n",
    "Again, Google provides me with a page that addresses the question:\n",
    "\n",
    "https://saturncloud.io/blog/how-to-find-all-duplicate-rows-in-a-pandas-dataframe/\n",
    "\n",
    "To remove the duplicates, do this search: \"how can I remove the duplicate rows in a DataFrame using Python\"\n",
    "\n",
    "This leads me to the following documentation.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acd1cc2f-2879-4839-8ac7-9b2bc306dfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate rows and print list of row numbers\n",
    "\n",
    "duplicates = df_bank_datefix[df_bank_datefix.duplicated()].index.tolist()  \n",
    "\n",
    "print(duplicates)\n",
    "\n",
    "# I do not see any duplicates. Hence, did not apply any remove function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cd8a5-c8bd-498c-b8b5-25dd74cdd2c6",
   "metadata": {},
   "source": [
    "5. Check whether the customers all have unique AccountIDs.  If not, provide the first example of a non-unique AccountId."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f3f46-b09e-4a48-a3f4-72e1d1ba77fc",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find the first non-unique item from a pandas Series in python\"\n",
    "\n",
    "By the way: why didn't I ask the question \"how can I check whether the customers all have unique AccountIDs\"?\n",
    "\n",
    "The problem would be that Google and ChatGPT don't know what \"customers\" you are talking about.  It's important to understand that the AccountIDs are a column of a DataFrame, and as such they are a Series.  Therefore, we should use the correct vocabulary and ask about a Series.  If you mess up and ask about a \"list\" instead of a Series, you _might_ get an answer that still works.  But it's better to get the vocabularly right.\n",
    "\n",
    "It's important to add \"in python\" because this task could be performed in many languages.\n",
    "\n",
    "ChatGPT gave me this suggestion: data[data.isin(data[data.duplicated()])].iloc[0]\n",
    "However, ChatGPT did not explain how this code worked and even claimed (falsely) that it was going to use the value_counts() function in the solution.  So although the code is correct, I personally found ChatGPT's answer very confusing.  You could, perhaps, ask ChatGPT to explain further how this code works.\n",
    "\n",
    "ChatGPT, \"How does this code work: data[data.isin(data[data.duplicated()])].iloc[0]\"\n",
    "\n",
    "On the other hand, Google leads me to the documentation for the duplicated() function:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Series.duplicated.html\n",
    "\n",
    "Here, I can see that when I really need is data.duplicated(keep = False), where \"data\" should be the Series in question.  However, this just gives me a Series of boolean values indicating which ones are duplicates.  I have to somehow know that extracting the numerical values instead of a Series of booleans involves boolean indexing: data\\[data.duplicated(keep = False)].\n",
    "\n",
    "So as usual, I'd suggest that a combination of Google, documentation, and ChatGPT will give you the best information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3825ba0-a790-42e0-94ad-df931dbad3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First non-unique AccountID: 86.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Isolating AccountID column from the customers table\n",
    "AccountID = df_bank_datefix[\"AccountID\"]\n",
    "\n",
    "# Check for duplicate AccountIDs\n",
    "duplicates = AccountID[AccountID.duplicated(keep=False)]\n",
    "\n",
    "if duplicates.empty:\n",
    "    print(\"All customers have unique AccountIDs.\")\n",
    "else:\n",
    "    first_non_unique = duplicates.iloc[0]\n",
    "    print(\"First non-unique AccountID:\", first_non_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68b682-fb52-4c2d-a172-5a76aa31395b",
   "metadata": {},
   "source": [
    "6. Count how many distinct AccountIDs there are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c31c5-e1d2-4387-bbe8-d156e731483a",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find out how many distinct items there are in a pandas Series using python\"\n",
    "\n",
    "This time Google provides me with a page that's specifically made to answer this question:\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-count-distinct-values-of-a-pandas-dataframe-column/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a5c497f-acca-4bea-b693-9e628ce40c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in AccountID: 64\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in 'AccountIDs' column \n",
    "\n",
    "n = len(pd.unique(df_bank_datefix[\"AccountID\"])) \n",
    "\n",
    "print(\"Number of unique values in AccountID:\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85058f11-6222-4511-92f6-537be74c4807",
   "metadata": {},
   "source": [
    "7. Remove the duplicate AccountIDs so that each AccountID appears only once.\n",
    "\n",
    "This will involve using data.duplicated() but this time without keep = False.  We don't want to drop all duplicates; we want to leave one example of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d904a7ec-a21c-498b-bd1c-1b8415a48f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustomerID  BirthDate          SSN  AccountID AccountOpened AccountType\n",
      "23        23.0 2021-12-11  939-09-9746       56.0    2071-09-01          cd\n",
      "24        24.0 1996-04-30  041-33-6362       24.0    2050-05-22          cd\n",
      "30        30.0 1963-04-14  168-31-0272       79.0    1970-04-19     savings\n",
      "38        38.0 1977-12-05  509-93-1650       24.0    2039-11-09          cd\n",
      "44        44.0 2018-06-12  275-51-1419       86.0    2095-12-10    checking\n",
      "45        45.0 2015-04-10  931-24-3971       61.0    2078-11-23     savings\n",
      "49        49.0 2007-10-28  494-36-1748       32.0    2069-08-14    checking\n",
      "50        50.0 1973-12-02  066-09-7361       11.0    2033-01-08     savings\n",
      "53        53.0 2001-02-18  716-06-9646       54.0    2063-01-25    checking\n",
      "58        58.0 2011-10-04  770-07-1306       83.0    2050-11-27          cd\n",
      "65        65.0 2004-10-10  632-10-8112       53.0    2071-12-12    checking\n",
      "66        66.0 1959-10-01  929-11-8240       29.0    1962-08-06          cd\n",
      "67        67.0 2019-05-11  392-50-0406       67.0    2036-06-20     savings\n",
      "68        68.0 1984-09-15  169-24-7872       35.0    2052-06-10    checking\n",
      "72        72.0 2008-07-03  371-57-0218       41.0    2023-01-17     savings\n",
      "73        73.0 2006-10-11  226-86-6547       23.0    2032-07-17          cd\n",
      "74        74.0 2023-01-19  086-36-1272        3.0    2093-12-24          cd\n",
      "75        75.0 1990-01-18  708-41-3884       46.0    2024-01-24     savings\n",
      "78        78.0 1973-08-10  020-16-6942        3.0    1990-01-24     savings\n",
      "79        79.0 2014-09-16  628-96-2584       31.0    2067-03-24     savings\n",
      "80        80.0 2006-04-28  763-71-6221        9.0    2029-03-10     savings\n",
      "81        81.0 2023-12-26  299-00-8770       10.0    2029-12-29     savings\n",
      "82        82.0 2002-02-20  085-93-3571       27.0    2014-12-14     savings\n",
      "84        84.0 2002-12-14  165-25-5019       71.0    2073-04-12          cd\n",
      "85        85.0 1994-08-16  911-34-2861       39.0    2047-12-05     savings\n",
      "86        86.0 1983-11-16  787-21-6240       61.0    2044-05-16     savings\n",
      "87        87.0 2001-01-08  026-22-8040       85.0    2015-05-15     savings\n",
      "89        89.0 1985-10-06  627-48-7327       44.0    2061-04-05    checking\n",
      "91        91.0 1997-10-16  627-23-0106       34.0    2027-10-14    checking\n",
      "92        92.0 1989-03-21  310-31-9554       88.0    1991-03-23     savings\n",
      "93        93.0 1964-05-18  596-66-1496       33.0    2023-01-01    checking\n",
      "97        97.0 1960-09-23  773-33-2797       75.0    1993-09-16          cd\n",
      "98        98.0 1975-08-17  846-64-7054       34.0    2032-12-25     savings\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate AccountIDs while keeping the first occurrence\n",
    "df_unique = df_bank_datefix[df_bank_datefix['AccountID'].duplicated(keep='first')]\n",
    "\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b55f40-7b54-462c-82a5-05960d970365",
   "metadata": {},
   "source": [
    "8. What are the mean, median, and mode customer age in years?  (Rounding down to the next lower age.)\n",
    "Are there any outliers?  (Customers with very large or very small ages, compared with the other ages?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8cb00-e676-4b21-9211-06f26edf5a61",
   "metadata": {},
   "source": [
    "Suggested Google search or ChatGPT prompt: \"how can I find out the mean, median, and mode of a pandas Series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fde44ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Age: 34.0\n",
      "Median Age: 33.0\n",
      "Mode Age: 28\n",
      "Outliers:\n",
      " Series([], Name: BirthDate, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Convert 'birthdate' column to datetime\n",
    "BirthDate = pd.to_datetime(df_bank_datefix['BirthDate'])\n",
    "\n",
    "# Calculate age by subtracting birthdate from the current date and converting the timedelta to years\n",
    "today = datetime.today()\n",
    "Age = BirthDate.apply(lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)))\n",
    "\n",
    "stats# Calculate mean, median, mode\n",
    "mean_age = np.floor(Age.mean())   \n",
    "median_age = np.floor(Age.median())  \n",
    "mode_age = np.floor(stats.mode(Age, keepdims=True)[0][0])  \n",
    "\n",
    "# Identify outliers using IQR (Interquartile Range)\n",
    "Q1 = Age.quantile(0.25)\n",
    "Q3 = Age.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = Age[(Age < lower_bound) | (Age > upper_bound)]\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Age: {mean_age}\")\n",
    "print(f\"Median Age: {median_age}\")\n",
    "print(f\"Mode Age: {mode_age}\")\n",
    "print(\"Outliers:\\n\", outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc3e88-aa16-4748-bf2d-b4c9672c7170",
   "metadata": {},
   "source": [
    "9. One-hot encode the AccountType column.  This means creating a new \"checking,\" \"savings\", and \"cd\" columns so that you can run machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ef9c041-9c44-4130-beec-c701ca1117a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustomerID  BirthDate          SSN  AccountID AccountOpened  \\\n",
      "2          2.0 1976-12-15  377-98-9839        NaN    2019-03-25   \n",
      "3          3.0 2003-10-18  474-05-7613       86.0    2004-03-02   \n",
      "4          4.0 1985-12-06  750-55-5509       77.0    2059-05-05   \n",
      "5          5.0 2008-02-29  671-43-0485       75.0    2025-05-03   \n",
      "6          6.0 1975-04-05  288-62-9296       56.0    2048-09-21   \n",
      "..         ...        ...          ...        ...           ...   \n",
      "94        94.0 1969-03-14  958-12-8308        5.0    2037-04-03   \n",
      "95        95.0 1975-09-23  607-97-1651       36.0    2011-07-24   \n",
      "96        96.0 1989-03-09  870-80-0364        0.0    2054-11-01   \n",
      "97        97.0 1960-09-23  773-33-2797       75.0    1993-09-16   \n",
      "98        98.0 1975-08-17  846-64-7054       34.0    2032-12-25   \n",
      "\n",
      "    AccountType_cd  AccountType_checking  AccountType_savings  \n",
      "2            False                  True                False  \n",
      "3             True                 False                False  \n",
      "4             True                 False                False  \n",
      "5            False                  True                False  \n",
      "6            False                 False                 True  \n",
      "..             ...                   ...                  ...  \n",
      "94           False                 False                 True  \n",
      "95           False                  True                False  \n",
      "96            True                 False                False  \n",
      "97            True                 False                False  \n",
      "98           False                 False                 True  \n",
      "\n",
      "[97 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_bank_datefix is already loaded as a DataFrame\n",
    "df_encoded = pd.get_dummies(df_bank_datefix, columns=['AccountType'], prefix='AccountType')\n",
    "\n",
    "# Display the resulting DataFrame with one-hot encoding\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55874415-e923-4179-86ea-502458cbcd7e",
   "metadata": {},
   "source": [
    "Now, change the cd, checking, and savings columns into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edda21a5-bb8c-4824-b320-1416dd807fc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '377-98-9839'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fill NaN values with 0 (or any other value that makes sense for your case)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m df_encoded\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_encoded_int \u001b[38;5;241m=\u001b[39m \u001b[43mdf_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Display the resulting DataFrame\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_encoded_int)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '377-98-9839'"
     ]
    }
   ],
   "source": [
    "# Fill NaN values with 0 (or any other value that makes sense for your case)\n",
    "df_encoded = df_encoded.fillna(0)\n",
    "\n",
    "df_encoded_int = df_encoded.astype(int)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_encoded_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e884d3e-1d76-42a2-9b2e-86471286aa51",
   "metadata": {},
   "source": [
    "10. Are there any other data values that do not seem right?  If not, give an example?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08a456-ae6d-4c79-8ca6-41f28d5cff20",
   "metadata": {},
   "source": [
    "I don't think Google or ChatGPT alone will help you here.  To answer the question, look at the columns and think about what relationships they should have with each other.  For example, it seems reasonable to expect that BirthDate would be no earlier than 120 years ago (it's unlikely that a customer would be this old.)  Now we can ask Google:\n",
    "\n",
    "\"How can I find out how long ago a pandas date is\"\n",
    "\n",
    "Google provides this helpful link, although it is not exactly the solution - you'll have to work with it a bit:\n",
    "\n",
    "https://stackoverflow.com/questions/26072087/pandas-number-of-days-elapsed-since-a-certain-date\n",
    "\n",
    "If you check, I think you'll find that all dates are more recent than 120 years ago.  What about the AccountOpened columns?  I see some obviously wrong dates there just by looking at the first few rows.\n",
    "\n",
    "Along those same lines, are there any birth dates that are too recent?  Do we think that any two year olds will have opened bank accounts?  How common do you think this is in real life?  How common is it in our data set?  Can you detect the two year olds opening bank accounts using just one column, or do you need two columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be984a-21d0-43e7-8a55-fb8a67b8a351",
   "metadata": {},
   "source": [
    "11. Use Matplotlib and/or Seaborn to analyse the ages at which customers open their account.  Is there a connection between the year they are born vs. the age at which they open the account?  Graph this in whatever way you think is best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84574af6-9f3a-481a-843a-877388973ef2",
   "metadata": {},
   "source": [
    "I asked Google and ChatGPT: \"How can I plot dates vs. dates in Matplotlib\".  This gave me a hard time at first - I had to tell ChatGPT it was giving me the wrong information because it tried to plot dates vs. numbers.  Eventually, I found out that you plot dates vs. dates in the same way you'd plot numbers vs. numbers.\n",
    "\n",
    "Think in terms of Storytelling With Data to plot these as best you can.  Once you've seen the result, try to think of the best way to plot the data so as to show the user what you want them to see.  Title the graph so as to display the lesson that you want the user to take away.\n",
    "Here are some options for the axes:\n",
    "\n",
    "1. A scatter or line plot: On the x-axis, the date they are born.  On the y-axis, the date they open the account.\n",
    "2. A scatter or line plot: On the x-axis, the date they are born.  On the y-axis, the age in years at which they open the account.\n",
    "3. A scatter or line plot: On the x-axis, they year (integer) they are born.  On the y-axis, the age in years at which they open the account.\n",
    "4. A histogram: on the x-axis, the age at which they open the account.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453acced-f7b1-4bb5-943d-716ae0505ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.gca() # get an \"Axes\" object to draw on; gca stands for \"get current Axes\"\n",
    "ax.scatter(df2[\"BirthDate\"], df2[\"AccountOpened\"]) # create a scatter plot based on these two dates\n",
    "ax.set_ylabel(\"Account Opened\") # label the y axis\n",
    "ax.set_xlabel(\"Birth Date\") # label the x axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2ca82-ea81-46e5-9002-8321987d08d9",
   "metadata": {},
   "source": [
    "# 4. Storytelling With Data graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e6940-4a0c-4b3e-93dd-460239bf9940",
   "metadata": {},
   "source": [
    "Choose any graph in the Introduction of Storytelling With Data.  Using matplotlib to reproduce it in a rough way.  I don't expect you to spend an enormous amount of time on this; I understand that you likely will not have time to re-create every feature of the graph.  However, if you're excited about learning to use matplotlib, this is a good way to do that.  You don't have to duplicate the exact values on the graph; just the same rough shape will be enough.  If you don't feel comfortable using matplotlib yet, do the best you can and write down what you tried or what Google searches you did to find the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023ff6f-f3c8-4df7-a7a6-191e70bcb362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
